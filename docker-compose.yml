# Docker Compose for Tail Sampling Selector with Iceberg Storage
# Stack: AutoMQ (Kafka-compatible) + Lakekeeper (Iceberg REST) + MinIO (S3-compatible)
#
# Usage:
#   docker compose up -d              # Start all services
#   docker compose --profile spark up # Include Spark for ad-hoc queries (optional, DataFusion used in-app)
#
# For production k3s with Garage, replace MinIO with Garage endpoint

services:
  # ============================================
  # Storage Layer: MinIO (S3-compatible)
  # Production: Replace with Garage endpoint
  # ============================================
  minio:
    image: minio/minio:latest
    container_name: minio
    hostname: minio
    ports:
      - "9000:9000"
      - "9001:9001"
    environment:
      MINIO_ROOT_USER: minioadmin
      MINIO_ROOT_PASSWORD: minioadmin123
    command: server /data --console-address ":9001"
    volumes:
      - minio-data:/data
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:9000/minio/health/live"]
      interval: 10s
      timeout: 5s
      retries: 5

  minio-init:
    image: minio/mc:latest
    container_name: minio-init
    depends_on:
      minio:
        condition: service_healthy
    entrypoint: >
      /bin/sh -c "
      mc alias set myminio http://minio:9000 minioadmin minioadmin123;
      mc mb --ignore-existing myminio/iceberg-warehouse;
      mc mb --ignore-existing myminio/automq-data;
      mc anonymous set public myminio/iceberg-warehouse;
      echo 'Buckets created successfully';
      exit 0;
      "

  # ============================================
  # Catalog Layer: Lakekeeper (Iceberg REST)
  # ============================================
  postgres:
    image: postgres:16-alpine
    container_name: lakekeeper-postgres
    hostname: postgres
    ports:
      - "5432:5432"
    environment:
      POSTGRES_USER: lakekeeper
      POSTGRES_PASSWORD: lakekeeper123
      POSTGRES_DB: lakekeeper
    volumes:
      - postgres-data:/var/lib/postgresql/data
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U lakekeeper -d lakekeeper"]
      interval: 5s
      timeout: 3s
      retries: 5

  lakekeeper-migrate:
    image: quay.io/lakekeeper/catalog:v0.10.4
    container_name: lakekeeper-migrate
    environment:
      LAKEKEEPER__PG_DATABASE_URL_READ: postgresql://lakekeeper:lakekeeper123@postgres:5432/lakekeeper
      LAKEKEEPER__PG_DATABASE_URL_WRITE: postgresql://lakekeeper:lakekeeper123@postgres:5432/lakekeeper
      LAKEKEEPER__PG_ENCRYPTION_KEY: "01234567890123456789012345678901"
    command: ["migrate"]
    depends_on:
      postgres:
        condition: service_healthy

  lakekeeper:
    image: quay.io/lakekeeper/catalog:v0.10.4
    container_name: lakekeeper
    hostname: lakekeeper
    ports:
      - "8181:8181"
    environment:
      LAKEKEEPER__PG_DATABASE_URL_READ: postgresql://lakekeeper:lakekeeper123@postgres:5432/lakekeeper
      LAKEKEEPER__PG_DATABASE_URL_WRITE: postgresql://lakekeeper:lakekeeper123@postgres:5432/lakekeeper
      LAKEKEEPER__PG_ENCRYPTION_KEY: "01234567890123456789012345678901"
      LAKEKEEPER__ENABLE_DEFAULT_PROJECT: "true"
      AWS_ENDPOINT_URL: http://minio:9000
      AWS_ACCESS_KEY_ID: minioadmin
      AWS_SECRET_ACCESS_KEY: minioadmin123
      AWS_REGION: us-east-1
      AWS_S3_ALLOW_UNSAFE_RENAME: "true"
      RUST_LOG: info,lakekeeper=debug
    command: ["serve"]
    depends_on:
      lakekeeper-migrate:
        condition: service_completed_successfully
      minio-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD", "/home/nonroot/lakekeeper", "healthcheck"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  lakekeeper-init:
    image: postman/newman:6-alpine
    container_name: lakekeeper-init
    depends_on:
      lakekeeper:
        condition: service_healthy
    volumes:
      - ./scripts/postman:/etc/newman:ro
    command:
      - run
      - /etc/newman/lakekeeper-init.postman_collection.json
      - --env-var
      - baseUrl=http://lakekeeper:8181
      - --env-var
      - minioHost=minio:9000
      - --bail

  # ============================================
  # Message Queue: AutoMQ (Kafka-compatible, S3-native)
  # ============================================
  kafka:
    image: automqinc/automq:latest
    container_name: kafka
    hostname: kafka
    stop_grace_period: 1m
    ports:
      - "9092:9092"
    environment:
      KAFKA_S3_ACCESS_KEY: minioadmin
      KAFKA_S3_SECRET_KEY: minioadmin123
      KAFKA_HEAP_OPTS: "-Xms512m -Xmx1g -XX:MetaspaceSize=96m -XX:MaxDirectMemorySize=512M"
      CLUSTER_ID: "MkU3OEVBNTcwNTJENDM2Qk"
    command:
      - bash
      - -c
      - |
        /opt/automq/kafka/bin/kafka-server-start.sh \
        /opt/automq/kafka/config/kraft/server.properties \
        --override cluster.id=$$CLUSTER_ID \
        --override node.id=1 \
        --override process.roles=broker,controller \
        --override controller.quorum.voters=1@kafka:9093 \
        --override controller.quorum.bootstrap.servers=kafka:9093 \
        --override listeners=INTERNAL://:29092,EXTERNAL://:9092,CONTROLLER://:9093 \
        --override advertised.listeners=INTERNAL://kafka:29092,EXTERNAL://127.0.0.1:9092 \
        --override listener.security.protocol.map=INTERNAL:PLAINTEXT,EXTERNAL:PLAINTEXT,CONTROLLER:PLAINTEXT \
        --override inter.broker.listener.name=INTERNAL \
        --override controller.listener.names=CONTROLLER \
        --override auto.create.topics.enable=true \
        --override offsets.topic.replication.factor=1 \
        --override s3.data.buckets='0@s3://automq-data?region=us-east-1&endpoint=http://minio:9000&pathStyle=true' \
        --override s3.ops.buckets='1@s3://automq-data?region=us-east-1&endpoint=http://minio:9000&pathStyle=true' \
        --override s3.wal.path='0@s3://automq-data?region=us-east-1&endpoint=http://minio:9000&pathStyle=true'
    depends_on:
      minio-init:
        condition: service_completed_successfully
      lakekeeper-init:
        condition: service_completed_successfully
    healthcheck:
      test: ["CMD-SHELL", "/opt/automq/kafka/bin/kafka-broker-api-versions.sh --bootstrap-server localhost:9092 || exit 1"]
      interval: 15s
      timeout: 10s
      retries: 10
      start_period: 60s
    volumes:
      - kafka-data:/opt/automq/kafka/data

  kafka-init:
    image: automqinc/automq:latest
    container_name: kafka-init
    depends_on:
      kafka:
        condition: service_healthy
    command: ["/opt/automq/kafka/bin/kafka-topics.sh", "--create", "--bootstrap-server", "kafka:29092", "--topic", "otel-traces-raw", "--partitions", "8", "--replication-factor", "1", "--if-not-exists"]

  # ============================================
  # Application: Tail Sampling Selector
  # ============================================
  redis:
    image: redis:7.2-alpine
    container_name: redis
    ports:
      - "6379:6379"
    command: redis-server --appendonly yes
    healthcheck:
      test: ["CMD", "redis-cli", "ping"]
      interval: 5s
      timeout: 3s
      retries: 5

  tail-sampling-selector:
    # Use pre-built image (docker build -f Dockerfile.cached -t tail-sampling-selector:local .)
    # Or build on-demand: docker compose build tail-sampling-selector
    image: tail-sampling-selector:local
    build:
      context: .
      dockerfile: Dockerfile.cached
    container_name: tail-sampling-selector
    ports:
      - "8080:8080"
      - "9090:9090"
    environment:
      TSS_ENVIRONMENT: development
      TSS__KAFKA__BROKERS: kafka:29092
      TSS__REDIS__URL: redis://redis:6379
      TSS__STORAGE__STORAGE_TYPE: iceberg
      TSS__STORAGE__ICEBERG__CATALOG_URI: http://lakekeeper:8181/catalog
      TSS__STORAGE__ICEBERG__WAREHOUSE: traces
      TSS__STORAGE__ICEBERG__NAMESPACE: default
      TSS__STORAGE__ICEBERG__TABLE_NAME: spans
      TSS__STORAGE__ICEBERG__S3_ENDPOINT: http://minio:9000
      TSS__STORAGE__ICEBERG__S3_ACCESS_KEY_ID: minioadmin
      TSS__STORAGE__ICEBERG__S3_SECRET_ACCESS_KEY: minioadmin123
      TSS__STORAGE__ICEBERG__S3_REGION: us-east-1
      TSS__STORAGE__ICEBERG__S3_PATH_STYLE: "true"
      TSS__STORAGE__ICEBERG__PROJECT_ID: "00000000-0000-0000-0000-000000000000"
      TSS__OBSERVABILITY__LOG_LEVEL: debug
      TSS__FORCE_SAMPLING__ENABLED: "true"
      RUST_LOG: debug
    depends_on:
      kafka-init:
        condition: service_completed_successfully
      redis:
        condition: service_healthy
      lakekeeper:
        condition: service_healthy
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/health/live"]
      interval: 10s
      timeout: 5s
      retries: 10
      start_period: 30s

  # ============================================
  # Observability: Prometheus (OTEL-compatible)
  # Metrics exported to Datadog via OTEL collector
  # ============================================
  prometheus:
    image: prom/prometheus:v2.48.0
    container_name: prometheus
    ports:
      - "9091:9090"
    volumes:
      - ./prometheus.yml:/etc/prometheus/prometheus.yml
    command:
      - '--config.file=/etc/prometheus/prometheus.yml'
      - '--web.enable-remote-write-receiver'

  # ============================================
  # Optional: OTEL Collector for Datadog export
  # ============================================
  otel-collector:
    image: otel/opentelemetry-collector-contrib:0.91.0
    container_name: otel-collector
    ports:
      - "4317:4317"
      - "4318:4318"
      - "8888:8888"
    volumes:
      - ./otel-collector-config.yaml:/etc/otelcol-contrib/config.yaml
    command: ["--config=/etc/otelcol-contrib/config.yaml"]
    environment:
      DD_API_KEY: ${DD_API_KEY:-}
      DD_SITE: ${DD_SITE:-datadoghq.com}
    profiles:
      - datadog

  # ============================================
  # Optional: Spark for ad-hoc Iceberg queries
  # ============================================
  spark:
    image: bitnami/spark:3.5
    container_name: spark
    ports:
      - "4040:4040"
      - "7077:7077"
    environment:
      - SPARK_MODE=master
      - SPARK_MASTER_HOST=spark
      - SPARK_CONF_spark.sql.extensions=org.apache.iceberg.spark.extensions.IcebergSparkSessionExtensions
      - SPARK_CONF_spark.sql.catalog.lakekeeper=org.apache.iceberg.spark.SparkCatalog
      - SPARK_CONF_spark.sql.catalog.lakekeeper.type=rest
      - SPARK_CONF_spark.sql.catalog.lakekeeper.uri=http://lakekeeper:8181/catalog
      - SPARK_CONF_spark.sql.catalog.lakekeeper.warehouse=traces
      - SPARK_CONF_spark.hadoop.fs.s3a.endpoint=http://minio:9000
      - SPARK_CONF_spark.hadoop.fs.s3a.access.key=minioadmin
      - SPARK_CONF_spark.hadoop.fs.s3a.secret.key=minioadmin123
      - SPARK_CONF_spark.hadoop.fs.s3a.path.style.access=true
    depends_on:
      - lakekeeper
      - minio
    profiles:
      - spark

volumes:
  minio-data:
  postgres-data:
  kafka-data:

networks:
  default:
    name: tail-sampling-network
